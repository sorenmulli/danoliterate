base_model: "meta-llama/Llama-2-7b-hf"

steps: 10_000
warmup_steps: 1000 
resume: false

optimizer: "adamw_torch"
lr: 5e-5
scheduler: "cosine_with_restarts"
weight_decay: 0.1

batch_size: 4
accumulation: 4
eval_batch_size: 8
eval_accumulation: 1

fp16: true

eval: true
eval_every: 1000
save_limit: 1000
log_every: 50

lora:
  enabled: false
  r: 8
  alpha: 32
  dropout: 0.1

data:
  datasets: ["uonlp/CulturaX:da", "DDSC/dagw_reddit_filtered_v1.0.0"]
  seed: 1887
  text_col: "text"
  test_examples: 10000
  validation_examples: 100
  context_tokens: 4096
  workers: 0

debug: false
